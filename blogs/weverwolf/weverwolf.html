




<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Graphs</title>
    
    <!-- Link to external CSS file -->
    <link rel="stylesheet" href="../../css/blogs_style.css">
</head>
<body>

<header>
    <h1>AI Agents Competing in a Weverwolf Game</h1>
</header>

<div class="container">

    <!-- Story Content Section -->
    <div class="story-content">
        
        <h2>
 Introduction
 </h2>
 
        <p>
            Large Lanaguage Models (LLMs) are the backbone of what we use today in ChatGPT or other generative word tool models. In simple terms, they are the brain of such system to work.
            Despite their success in doing many language understanding tasks, there any many papers and blog posts [1] evaluating the reasoning abilities of LLMs. That is a major
            challenge in 2025 to have an LLM to be fully capable of doing reasining that we expect. In old days before 2022, for any new problems
            in training a pattern if there was a slightly shift in data pattern, the whole settup and data gathering should have been redefined to compensate for such shift.
            Reasining, on another hand, helps to just figure this shift out and do the job by avoiding the repeatitive tasks. Such reasoning should extrapolate 
            the knowledge we have already gathered in a task to extend the understading and knowledge to other task without
            training everything from scratch.
            <br>

            One way to see how LLMs are doing the reasoning is to develop an application where AI-Agents are verbally fighting or challenging each other
            based on reasonings they each are equipped with. Perhaps one of the best benchmarks is to use multiple AI-Agents to compete in a game like weverwolf  to 
            evalude their reasonings and self evauations.
            
            <br>
            In weverwolf game, or Mafia game, palyers are integrate to solving a case where a few Mafias (wolves) are hidden in a group of 
            villegers. In this game which is governed by an asymetrical knowledge between villegers and wolfs,   the task for these wolves is to pretend that they are villegers and  blame the acutal villegers
            of being a wolf in the game. This should be verfied by villegers through the clues they find in the game to reveal the true charecter of 
            players. Villegers, however,  need to team up and find those wolves hidden among themselves, convince each other  and collectively vote for them
            to  compromise a wolf's true identity. 
            
            <br>
            The significance of using AI-Agents backed by LLMs is that you can see the power of them in reasonings and how well
            they can be recruited for such tasks.
            For more information about how this game is played just visit [2].

            <br>
            </p>


             <p>
 <img src="../../assets/images/blog_images/wolves2.png" alt="Data Plot" class="custom-img">
 
 </p>
 
      <h2>
 Implementation
 </h2>
<p>
 
    To design the game, 6 players are defined as two wolves and 4 villegers to compete. The wolves know their teamates and each one's role
    is hard coded in the game.
 To implement this game, LangGraph is used for conversational orchestration. 
 What it does is it actually help you mange the turns in speaking and use LLMs in a stateful graph to see what the next path
 in the game is. This manging turns and decision making is left to a moderator node (named God) to manage everything automatically.
  See the code in <a href="">here</a>. 
  
   <img src="../../assets/images/blog_images/wolves3.png" alt="Data Plot" class="custom-img">


 </p>
<br>

   <h2>
 Challenges
 </h2>
  <li>
 Using light llm model like deepseek (deepseek-coder:1.3b) is quite limited and it makes alot of mistakes in targeting
 teamates. This code here is run using LLAMA3 on Groq for faster resposnes.
</li>
 <li>
 After a few rounds of talkings, the amount of data is collected is so dramatic.
No all models allow using a long text input for feeding into llm to get the analysis.
</li>
<li>
If rounds of game increases the some APIs ban you of using more of their abilites.
</li>
<li>
One can use Ollam for such limitation, but using Ollama takes 30 sec for each speaker to get their comments.
However, using APIs like what Groq offers, it only takes seconds to get a reply.
</li>
 <h2>
 Resources
 </h2>
 <p>

            [1] https://medium.com/@lightetal/but-what-exactly-is-reasoning-7810c63e341a
            <br>    
            [2] https://playwerewolf.co/pages/rules.
 </p>

        <!-- Author Section -->
    <div class="author">
        <h4 class="author">Author: Sobhan, Dec 2023</h4>
    </div>

</div>

<footer>
    <p>Â© 2024 Sobhan - All rights reserved</p>
</footer>

</body>
</html>


</li>